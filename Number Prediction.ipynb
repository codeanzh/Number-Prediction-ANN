{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "f=gzip.open('mnist.pkl.gz','rb')\n",
    "u=pickle._Unpickler(f)\n",
    "u.encoding='latin1'\n",
    "training_data,validation_data,test_data=u.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoder function\n",
    "def one_hot_encoder(x):\n",
    "    one_hot=np.zeros((len(x),10))\n",
    "    rows=np.arange(x.size)\n",
    "    one_hot[rows,x]=1\n",
    "    return one_hot.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training data\n",
    "x_training_data=np.array(training_data[0]).T\n",
    "y_training_data=one_hot_encoder(np.array(training_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test data\n",
    "x_test_data=np.array(test_data[0]).T\n",
    "y_test_data=one_hot_encoder(np.array(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get devlopment data\n",
    "x_dev_data=np.array(validation_data[0]).T\n",
    "y_dev_data=one_hot_encoder(np.array(validation_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions and derivative\n",
    "def softmax(z):\n",
    "    return np.exp(z)/np.sum(np.exp(z),axis=0,keepdims=True)\n",
    "\n",
    "def relu(z):\n",
    "    return np.where(z>0,z,0.001*z)\n",
    "\n",
    "def relu_(z):\n",
    "    return np.where(z>0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def cost(y,yhat,m):\n",
    "    return -1*np.sum(y*np.log(yhat))/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise epoch\n",
    "def epoch(training_size,epoch_size,parameter,x1,y1):\n",
    "    if training_size%epoch_size==0:\n",
    "        size=training_size/epoch_size\n",
    "        parameter[\"num_epoch\"]=size\n",
    "        for i in range(1,size+1):\n",
    "            parameter[\"x\"+str(i)]=x1[:,(i-1)*epoch_size:i*epoch_size]\n",
    "            parameter[\"y\"+str(i)]=y1[:,(i-1)*epoch_size:i*epoch_size]\n",
    "        return parameter\n",
    "    size=training_size//epoch_size\n",
    "    parameter[\"num_epoch\"]=size+1\n",
    "    for i in range(1,size+1):\n",
    "        parameter[\"x\"+str(i)]=x1[:,(i-1)*epoch_size:i*epoch_size]\n",
    "        parameter[\"y\"+str(i)]=y1[:,(i-1)*epoch_size:i*epoch_size]\n",
    "    parameter[\"x\"+str(size+1)]=x1[:,size*epoch_size:-1]\n",
    "    parameter[\"y\"+str(size+1)]=y1[:,size*epoch_size:-1]\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise layer\n",
    "def initialise_layer(x):\n",
    "    layer=[x.shape[0],64,128,64,64,10]\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise weights and bias\n",
    "def initialise_wb(layer,parameter,L):\n",
    "    for l in range(1,L+1):\n",
    "        parameter[\"w\"+str(l)]=np.random.randn(layer[l],layer[l-1])*((2/layer[l-1])**0.5)\n",
    "        parameter[\"b\"+str(l)]=np.zeros((layer[l],1))\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propagation\n",
    "def forward_propagation(parameter,L):\n",
    "    for l in range(1,L):\n",
    "        parameter[\"a\"+str(l)]=relu(np.dot(parameter[\"w\"+str(l)],parameter[\"a\"+str(l-1)])+parameter[\"b\"+str(l)])\n",
    "    parameter[\"a\"+str(L)]=softmax(np.dot(parameter[\"w\"+str(L)],parameter[\"a\"+str(L-1)])+parameter[\"b\"+str(L)])\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back propagation\n",
    "def back_propagation(parameter,L,y,m):\n",
    "    parameter[\"dz\"+str(L)]=parameter[\"a\"+str(L)]-y\n",
    "    parameter[\"dw\"+str(L)]=np.dot(parameter[\"dz\"+str(L)],parameter[\"a\"+str(L-1)].T)/m\n",
    "    parameter[\"db\"+str(L)]=np.sum(parameter[\"dz\"+str(L)],axis=1,keepdims=True)/m\n",
    "    for l in reversed(range(1,L)):\n",
    "        parameter[\"dz\"+str(l)]=np.dot(parameter[\"w\"+str(l+1)].T,parameter[\"dz\"+str(l+1)])*relu_(parameter[\"a\"+str(l)])\n",
    "        parameter[\"dw\"+str(l)]=np.dot(parameter[\"dz\"+str(l)],parameter[\"a\"+str(l-1)].T)/m\n",
    "        parameter[\"db\"+str(l)]=np.sum(parameter[\"dz\"+str(l)],axis=1,keepdims=True)/m\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradiant descent\n",
    "def gradiant_discent(parameter,alpha,L):\n",
    "    for l in range(1,L+1):\n",
    "        parameter[\"w\"+str(l)]=parameter[\"w\"+str(l)]-alpha*parameter[\"dw\"+str(l)]\n",
    "        parameter[\"b\"+str(l)]=parameter[\"b\"+str(l)]-alpha*parameter[\"db\"+str(l)]\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "def start_training(parameter,L,alpha):\n",
    "    for i in range(1,parameter[\"num_epoch\"]+1):\n",
    "        parameter[\"a0\"]=parameter[\"x\"+str(i)]\n",
    "        parameter=forward_propagation(parameter,L)\n",
    "        parameter=back_propagation(parameter,L,parameter[\"y\"+str(i)],parameter[\"y\"+str(i)].shape[1])\n",
    "        parameter=gradiant_discent(parameter,alpha,L)\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on dev data\n",
    "def start_test(parameter,L,m,y):\n",
    "    parameter=forward_propagation(parameter,L)\n",
    "    acc=0\n",
    "    for i in range(y.shape[1]):\n",
    "        max_=0\n",
    "        for j in range(10):\n",
    "            max_=max_ if parameter[\"a\"+str(L)][max_][i]>parameter[\"a\"+str(L)][j][i] else j\n",
    "        if y[max_][i]==1:\n",
    "            acc+=1\n",
    "    print(\"Accuracy on dev set is\",acc*100/y.shape[1],\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "def train():\n",
    "    x1=x_training_data\n",
    "    y1=y_training_data\n",
    "    layer=initialise_layer(x1)\n",
    "    L=len(layer)-1\n",
    "    parameter={}\n",
    "    parameter=initialise_wb(layer,parameter,L)\n",
    "    epoch_size=256\n",
    "    parameter=epoch(x1.shape[1],epoch_size,parameter,x1,y1)\n",
    "    num_iteration=150\n",
    "    alpha=0.005\n",
    "    x=x_dev_data\n",
    "    y=y_dev_data\n",
    "    for i in range(1,num_iteration+1):\n",
    "        parameter=start_training(parameter,L,alpha)\n",
    "        if i%5==0:\n",
    "            parameter[\"a0\"]=x1\n",
    "            parameter=forward_propagation(parameter,L)\n",
    "            print(\"At\",i,\"th iteration cost ===>>>\",cost(y1,parameter[\"a\"+str(L)],y1.shape[1]))\n",
    "            acc=0\n",
    "            for k in range(y1.shape[1]):\n",
    "                max_=0\n",
    "                for j in range(10):\n",
    "                    max_=max_ if parameter[\"a\"+str(L)][max_][k]>parameter[\"a\"+str(L)][j][k] else j\n",
    "                if y1[max_][k]==1:\n",
    "                    acc+=1\n",
    "            print(\"Accuracy on training set is\",acc*100/y1.shape[1],\"%\")\n",
    "            m=x.shape[1]\n",
    "            parameter[\"a0\"]=x\n",
    "            start_test(parameter,L,m,y)\n",
    "    return parameter,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 5 th iteration cost ===>>> 0.4405967524924979\n",
      "Accuracy on training set is 87.194 %\n",
      "Accuracy on dev set is 88.41 %\n",
      "At 10 th iteration cost ===>>> 0.31475436119176475\n",
      "Accuracy on training set is 90.808 %\n",
      "Accuracy on dev set is 91.39 %\n",
      "At 15 th iteration cost ===>>> 0.2647005223394879\n",
      "Accuracy on training set is 92.156 %\n",
      "Accuracy on dev set is 92.56 %\n",
      "At 20 th iteration cost ===>>> 0.23280301166335698\n",
      "Accuracy on training set is 93.12 %\n",
      "Accuracy on dev set is 93.5 %\n",
      "At 25 th iteration cost ===>>> 0.20910342769362913\n",
      "Accuracy on training set is 93.848 %\n",
      "Accuracy on dev set is 93.98 %\n",
      "At 30 th iteration cost ===>>> 0.18982712735206303\n",
      "Accuracy on training set is 94.452 %\n",
      "Accuracy on dev set is 94.61 %\n",
      "At 35 th iteration cost ===>>> 0.17440025571860937\n",
      "Accuracy on training set is 94.882 %\n",
      "Accuracy on dev set is 94.95 %\n",
      "At 40 th iteration cost ===>>> 0.16147248494082\n",
      "Accuracy on training set is 95.242 %\n",
      "Accuracy on dev set is 95.23 %\n",
      "At 45 th iteration cost ===>>> 0.15032866477343462\n",
      "Accuracy on training set is 95.618 %\n",
      "Accuracy on dev set is 95.52 %\n",
      "At 50 th iteration cost ===>>> 0.14061579211113842\n",
      "Accuracy on training set is 95.912 %\n",
      "Accuracy on dev set is 95.74 %\n",
      "At 55 th iteration cost ===>>> 0.13204424338783977\n",
      "Accuracy on training set is 96.172 %\n",
      "Accuracy on dev set is 95.92 %\n",
      "At 60 th iteration cost ===>>> 0.12442467510960549\n",
      "Accuracy on training set is 96.364 %\n",
      "Accuracy on dev set is 96.1 %\n",
      "At 65 th iteration cost ===>>> 0.11755766992265625\n",
      "Accuracy on training set is 96.61 %\n",
      "Accuracy on dev set is 96.18 %\n",
      "At 70 th iteration cost ===>>> 0.11134565992185445\n",
      "Accuracy on training set is 96.808 %\n",
      "Accuracy on dev set is 96.26 %\n",
      "At 75 th iteration cost ===>>> 0.10563544531832206\n",
      "Accuracy on training set is 96.964 %\n",
      "Accuracy on dev set is 96.35 %\n",
      "At 80 th iteration cost ===>>> 0.10046039419000315\n",
      "Accuracy on training set is 97.11 %\n",
      "Accuracy on dev set is 96.57 %\n",
      "At 85 th iteration cost ===>>> 0.09575932054464938\n",
      "Accuracy on training set is 97.228 %\n",
      "Accuracy on dev set is 96.67 %\n",
      "At 90 th iteration cost ===>>> 0.09135873750918025\n",
      "Accuracy on training set is 97.38 %\n",
      "Accuracy on dev set is 96.71 %\n",
      "At 95 th iteration cost ===>>> 0.08724309137811087\n",
      "Accuracy on training set is 97.526 %\n",
      "Accuracy on dev set is 96.8 %\n",
      "At 100 th iteration cost ===>>> 0.08341442505302436\n",
      "Accuracy on training set is 97.67 %\n",
      "Accuracy on dev set is 96.83 %\n",
      "At 105 th iteration cost ===>>> 0.07982480170739006\n",
      "Accuracy on training set is 97.786 %\n",
      "Accuracy on dev set is 96.81 %\n",
      "At 110 th iteration cost ===>>> 0.07649371564523565\n",
      "Accuracy on training set is 97.868 %\n",
      "Accuracy on dev set is 96.87 %\n",
      "At 115 th iteration cost ===>>> 0.07334652838211064\n",
      "Accuracy on training set is 97.966 %\n",
      "Accuracy on dev set is 96.89 %\n",
      "At 120 th iteration cost ===>>> 0.0704384996354262\n",
      "Accuracy on training set is 98.046 %\n",
      "Accuracy on dev set is 96.92 %\n",
      "At 125 th iteration cost ===>>> 0.06771569500445128\n",
      "Accuracy on training set is 98.136 %\n",
      "Accuracy on dev set is 96.95 %\n",
      "At 130 th iteration cost ===>>> 0.06515528480519489\n",
      "Accuracy on training set is 98.226 %\n",
      "Accuracy on dev set is 97.01 %\n",
      "At 135 th iteration cost ===>>> 0.0626932686521223\n",
      "Accuracy on training set is 98.306 %\n",
      "Accuracy on dev set is 97.06 %\n",
      "At 140 th iteration cost ===>>> 0.06037495683654806\n",
      "Accuracy on training set is 98.374 %\n",
      "Accuracy on dev set is 97.09 %\n",
      "At 145 th iteration cost ===>>> 0.05816098859750034\n",
      "Accuracy on training set is 98.456 %\n",
      "Accuracy on dev set is 97.1 %\n",
      "At 150 th iteration cost ===>>> 0.05605288780394839\n",
      "Accuracy on training set is 98.538 %\n",
      "Accuracy on dev set is 97.13 %\n"
     ]
    }
   ],
   "source": [
    "#application\n",
    "parameter,L=train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 96.93 %\n"
     ]
    }
   ],
   "source": [
    "#test on test data\n",
    "parameter[\"a0\"]=x_test_data\n",
    "y=y_test_data\n",
    "parameter=forward_propagation(parameter,L)\n",
    "acc=0\n",
    "for i in range(y.shape[1]):\n",
    "    max_=0\n",
    "    for j in range(10):\n",
    "        max_=max_ if parameter[\"a\"+str(L)][max_][i]>parameter[\"a\"+str(L)][j][i] else j\n",
    "    if y[max_][i]==1:\n",
    "        acc+=1\n",
    "print(\"Accuracy on test set is\",acc*100/y.shape[1],\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLLECTING DATA\n",
    "weight=[]\n",
    "bias=[]\n",
    "for l in range(L):\n",
    "    weight.append(parameter[\"w\"+str(l+1)])\n",
    "    bias.append(parameter[\"b\"+str(l+1)])\n",
    "pickle.dump(weight,open(\"weight.p\",\"wb\"))\n",
    "pickle.dump(bias,open(\"bias.p\",\"wb\"))\n",
    "pickle.dump(L,open(\"length.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Number is  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testing data\n",
    "x=x_test_data.T[2022].reshape(784,1)\n",
    "plt.imshow(x.reshape(28,28))\n",
    "parameter[\"a0\"]=x\n",
    "parameter=forward_propagation(parameter,L)\n",
    "max_=0\n",
    "for i in range(10):\n",
    "    max_=max_ if parameter[\"a\"+str(L)][max_][0]>parameter[\"a\"+str(L)][i][0] else i\n",
    "print(\"Predicted Number is \",max_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
